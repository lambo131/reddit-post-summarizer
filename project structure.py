"""
secrets pkl key names:
secrets = {
    'openai_api_key': openai_api_key,
    'reddit_secret': secret,
    'client_id': client_id,
    'user_agent': user_agent,
}
classes:
    CommentScrapper():
        fields:
            # reddit api stuff
            client_id
            client_secret 
            user_agent

            # scraper
            token_limit   # maximum token of comments to be scraped
            num_comment_layer   # horizontal priority settings
            max_depth   # maximum comment scrape depth setting

            discussions = None # discussions scrapped last time 

            debug = False # for enable debug printing

        interface methods:
            def get_post_id(url)
                # returns the id part in the url

            def extract_text(self, discussions):
                # returns the discussion in a llm-ready string

            def scrape_post(post_id)->None:
                # saves submission in the class. Must call before calling:
                    - extract_discussions(post_id)
            
            def extract_discussions(self, post_id)->None:
                # extracts discussions in the submission. Must call before calling:
                    - get_all_discussions()
                    - get_discussions_by_author()
                    - get_discussions_by_range()
                    - get_discussions_by_index())
                
            def get_all_discussions(self, post_id):
                # returns all scrapped discussions from post
                return [Discussion]
    
            def get_discussions_by_author(self, post_id, authors:List[str]):
                # returns scrapped discussions of the list of authors
                return [Discussion]

            def get_discussions_by_index(self, post_id, indexes:List[int]):
                # returns scrapped discussions of selected index
                return [Discussion]
        
        private methods:

            def remove_extra_lines(str):
                # removes extra "\n" in str
            
            def str_token_count(str):
                # counts string token count

            scrape_comments(post_id):
                '''
                scrapes comments from post with horizontal priority
                etc, scrapes 10 first layer comments before moving to 
                second layer
                '''
                return scrapped_comments: list[MyComment]
            
            group_comments(group, depth):
                '''
                groups by first layer comment
                '''
                return discussions: list[list[MyComment]]
        
        class 
            MyComment()
                fields:
                    comment: reddit.praw.commetns
                    pos: list[int]
                    depth: int
                # used to queue comments when scrapping
            
            Discussion()
                # used to save discussion content and author
                fields:
                    grouped_comments: all sub-comments in a sequence ordered list
                    author: author for the discussion(aka: parent comment)
                    discussion_num: position number of the discussion(1 for the first parent comment)
                    num_comments: number of sub-comments in the discussion
                    char_count: number of characters of the entire discussion
    ---------------------------------
    bench():
        field:
            post_id:
            post_title:
            scrapper: The 'CommentScrapper' class containing submission and discussions
            selected_discussions: discussions selected by the user
            summary: summary generated by llm

    
            

    ---------------------------------

    Generator():
        field:
            llm
            template    # prompt template for llm

        methods:
            def get_summary(title, text):
                # generates summary and reflection of reddit post
                return str

            def get_templates():
                # private class for initializing the prompt templates
    ---------------------------------
    
    


"""